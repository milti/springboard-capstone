#length(tweeters)
botDS <- left_join(botDS, shredDF, by = "screenName")
groupedTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)
library(quanteda)
#using quanteda pkg - using the _TTR_ field as sole score
groupedTweetsDF$langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))$TTR
botDiv <- groupedTweetsDF %>%
group_by(screenName) %>%
summarise(meanDiv = mean(langDiv))
botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup
#library(twitteR)
#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
#accts <- unlist(botDS$screenName)
#latestStat <- lookupUsers(accts)
latestStat <- readRDS("capstone dataset/latestStat")
latestStatDF <- twListToDF(latestStat)
latestStatDF$description <- iconv(latestStatDF$description, "latin1", "ASCII")
latestStatDF$name <- iconv(latestStatDF$name, "latin1", "ASCII")
latestStatDF$location <- iconv(latestStatDF$location, "latin1", "ASCII")
botDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(botDS$acct_created)
botDS$acct_age <- as.numeric(botDS$acct_age, units = "mins")
botDS <- left_join(botDS[-4], latestStatDF[, c("screenName", "statusesCount")], by = "screenName")
botDS$mean_time_betwn_tweets = botDS$acct_age/botDS$statusesCount #time measured in minutes
botDS <- botDS[, c(1, 6, 14, 16, 15, 18, 3, 12, 13, 4, 7, 9, 5, 8, 10, 11)]
names(botDS)
botDS$mean_time_betwn_tweets
botDS$statusesCount
botDS$statusesCount[which(is.na())]
botDS$statusesCount[which(is.na)]
botDS$statusesCount == NA
botDS$statusesCount != NA
which(is.na(botDS$statusesCount))
noStats <- which(is.na(botDS$statusesCount))
botDS$screenName[noStats]
unique(botDS$screenName[noStats])
noTweets <- unique(botDS$screenName[noStats])
lookAgain <- lookupUsers(noTweets)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "dMs3guHk4y6DDdztO0JDmUTqB"
consumerSecret <- "csna8h6XWQMd3ZppMBCUuNNXDTuBAVJLNK7QphZRCd5plkES0z"
accessToken <- "1240280636-PTXARRUrytYtijYXyPWKptD9cHSCMzlAujQkATI"
accessTokenSecret <- "uo8INEJbhhe43AIXfSs5veSZ6i7IHbh8Tn1LLlYTJqOm2"
handle <- "conjja"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessTokenSecret)
knitr::opts_chunk$set(echo = TRUE)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "gI20zgelMl60fP7KE3GWtHTBl"
consumerSecret <- "hZDUuFonXapqeO0puVSV2RyaqJmMCziDRXKWOg0RldL135LHy4"
accessToken <- "1240280636-PTXARRUrytYtijYXyPWKptD9cHSCMzlAujQkATI"
accessTokenSecret <- "uo8INEJbhhe43AIXfSs5veSZ6i7IHbh8Tn1LLlYTJqOm2"
handle <- "conjja"
se
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessTokenSecret)
lookAgain <- lookupUsers(noTweets)
??Rtweets
library(rtweet)
lookAgain <- users_data(noTweets)
lookAgain <- users_data('conjja')
lookAgain <- getUser('conjja')
lookAgain
lookAgain <- lookupUsers(noTweets)
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessTokenSecret)
lookAgain <- lookupUsers(noTweets)
botDS21mar <- readRDS("capstone dataset/botDS.21march")
botDS21mar <- readRDS("capstone dataset.OLD/botDS.21march")
names(botDS21mar)
botDS21mar <- botDS21mar[, c(1, 6, 14, 16, 15, 18, 3, 12, 13, 4, 7, 9, 5, 8, 10, 11)]
names(botDS21mar)
names(botDS)
oldbot <- readRDS("capstone dataset.OLD/botDS.before.shredDF")
names(oldbot)
botAcctlist <- readRDS("capstone dataset/botAcctlist")
names(botAcctlist)
botAcctlist$description <- iconv(botAcctlist$description, "latin1", "ASCII")
botAcctlist$name <- iconv(botAcctlist$name, "latin1", "ASCII")
str(botAcctlist)
library(tidyverse)
library(qdapRegex)
recentTweetsDF <- readRDS("capstone dataset/recentTweetsDF")
recentTweetsDF$text <- iconv(recentTweetsDF$text, "latin1", "ASCII")
AppURL <- rm_between_multiple(recentTweetsDF$statusSource,"<",">")
recentTweetsDF$App <- unlist(AppURL)
appcount <- recentTweetsDF %>%
group_by(App) %>%
summarize(Count=n()) %>%
arrange(desc(Count))
recentTweetsDF <- left_join(recentTweetsDF,appcount)
recentTweetsDF$BoN <- ifelse(recentTweetsDF$Count>4,0,1)
shredDF <- recentTweetsDF %>% select(screenName, App, Count, BoN)
botDS <- data.frame(botAcctlist$screenName, botAcctlist$id, botAcctlist$created, botAcctlist$statusesCount, langDiv = 0, mean_time_betwn_tweets = 0, bot = 0)
columnnames <- names(botDS)
columnnames[1] <- "screenName"
columnnames[2] <- "ID"
columnnames[3] <- "acct_created"
columnnames[4] <- "statusesCount"
colnames(botDS) <- columnnames
tweetsRT <- filter(recentTweetsDF, isRetweet == "TRUE")
tweetsOPEN <- filter(recentTweetsDF, isRetweet != "TRUE")
#tweeters <- unique(tweetsOPEN$screenName)
#length(tweeters)
botDS <- left_join(botDS, shredDF, by = "screenName")
groupedTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)
library(quanteda)
#using quanteda pkg - using the _TTR_ field as sole score
groupedTweetsDF$langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))$TTR
botDiv <- groupedTweetsDF %>%
group_by(screenName) %>%
summarise(meanDiv = mean(langDiv))
botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup
#library(twitteR)
#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
#accts <- unlist(botDS$screenName)
#latestStat <- lookupUsers(accts)
latestStat <- readRDS("capstone dataset/latestStat")
latestStatDF <- twListToDF(latestStat)
botDS <- data.frame(botAcctlist$screenName, botAcctlist$id, botAcctlist$created, botAcctlist$statusesCount, langDiv = 0, mean_time_betwn_tweets = 0, bot = 0)
columnnames <- names(botDS)
columnnames[1] <- "screenName"
columnnames[2] <- "ID"
columnnames[3] <- "acct_created"
columnnames[4] <- "statusesCount"
colnames(botDS) <- columnnames
tweetsRT <- filter(recentTweetsDF, isRetweet == "TRUE")
tweetsOPEN <- filter(recentTweetsDF, isRetweet != "TRUE")
#tweeters <- unique(tweetsOPEN$screenName)
#length(tweeters)
botDS <- left_join(botDS, shredDF, by = "screenName")
groupedTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)
library(quanteda)
#using quanteda pkg - using the _TTR_ field as sole score
groupedTweetsDF$langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))$TTR
botDiv <- groupedTweetsDF %>%
group_by(screenName) %>%
summarise(meanDiv = mean(langDiv))
botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup
library(twitteR)
#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
#accts <- unlist(botDS$screenName)
#latestStat <- lookupUsers(accts)
latestStat <- readRDS("capstone dataset/latestStat")
latestStatDF <- twListToDF(latestStat)
latestStatDF$description <- iconv(latestStatDF$description, "latin1", "ASCII")
latestStatDF$name <- iconv(latestStatDF$name, "latin1", "ASCII")
latestStatDF$location <- iconv(latestStatDF$location, "latin1", "ASCII")
botDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(botDS$acct_created)
botDS <- data.frame(botAcctlist$screenName, botAcctlist$id, botAcctlist$created, botAcctlist$statusesCount, langDiv = 0, mean_time_betwn_tweets = 0, bot = 0)
columnnames <- names(botDS)
columnnames[1] <- "screenName"
columnnames[2] <- "ID"
columnnames[3] <- "acct_created"
columnnames[4] <- "statusesCount"
colnames(botDS) <- columnnames
tweetsRT <- filter(recentTweetsDF, isRetweet == "TRUE")
tweetsOPEN <- filter(recentTweetsDF, isRetweet != "TRUE")
#tweeters <- unique(tweetsOPEN$screenName)
#length(tweeters)
botDS <- left_join(botDS, shredDF, by = "screenName")
groupedTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)
library(quanteda)
#using quanteda pkg - using the _TTR_ field as sole score
groupedTweetsDF$langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))$TTR
botDiv <- groupedTweetsDF %>%
group_by(screenName) %>%
summarise(meanDiv = mean(langDiv))
botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup
library(twitteR)
#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
#accts <- unlist(botDS$screenName)
#latestStat <- lookupUsers(accts)
latestStat <- readRDS("capstone dataset/latestStat")
latestStatDF <- twListToDF(latestStat)
latestStatDF$description <- iconv(latestStatDF$description, "latin1", "ASCII")
latestStatDF$name <- iconv(latestStatDF$name, "latin1", "ASCII")
latestStatDF$location <- iconv(latestStatDF$location, "latin1", "ASCII")
anchorDate <- as.Date("2018-01-12")
botDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(botDS$acct_created)
botDS$acct_age <- as.numeric(botDS$acct_age, units = "mins")
botDS <- left_join(botDS[-4], latestStatDF[, c("screenName", "statusesCount")], by = "screenName")
botDS$mean_time_betwn_tweets = botDS$acct_age/botDS$statusesCount #time measured in minutes
botDS <- botDS[, c(1, 6, 14, 16, 15, 18, 3, 12, 13, 4, 7, 9, 5, 8, 10, 11)]
names(latestStatDF)
names(botDS)
botDS <- data.frame(botAcctlist$screenName, botAcctlist$id, botAcctlist$created, botAcctlist$statusesCount, langDiv = 0, mean_time_betwn_tweets = 0, bot = 0)
columnnames <- names(botDS)
columnnames[1] <- "screenName"
columnnames[2] <- "ID"
columnnames[3] <- "acct_created"
columnnames[4] <- "statusesCount"
colnames(botDS) <- columnnames
tweetsRT <- filter(recentTweetsDF, isRetweet == "TRUE")
tweetsOPEN <- filter(recentTweetsDF, isRetweet != "TRUE")
#tweeters <- unique(tweetsOPEN$screenName)
#length(tweeters)
botDS <- left_join(botDS, shredDF, by = "screenName")
groupedTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)
library(quanteda)
#using quanteda pkg - using the _TTR_ field as sole score
groupedTweetsDF$langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))$TTR
botDiv <- groupedTweetsDF %>%
group_by(screenName) %>%
summarise(meanDiv = mean(langDiv))
botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup
library(twitteR)
#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
#accts <- unlist(botDS$screenName)
#latestStat <- lookupUsers(accts)
latestStat <- readRDS("capstone dataset/latestStat")
latestStatDF <- twListToDF(latestStat)
latestStatDF$description <- iconv(latestStatDF$description, "latin1", "ASCII")
latestStatDF$name <- iconv(latestStatDF$name, "latin1", "ASCII")
latestStatDF$location <- iconv(latestStatDF$location, "latin1", "ASCII")
anchorDate <- as.Date("2018-01-12")
botDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(botDS$acct_created)
botDS$acct_age <- as.numeric(botDS$acct_age, units = "mins")
#botDS <- left_join(botDS[-4], latestStatDF[, c("screenName", "statusesCount")], by = "screenName")
botDS <- left_join(botDS[-4], latestStatDF[, c("screenName", "statusesCount")], by = "screenName")
botDS$mean_time_betwn_tweets = botDS$acct_age/botDS$statusesCount #time measured in minutes
botDS <- botDS[, c(1, 6, 14, 16, 15, 18, 3, 12, 13, 4, 7, 9, 5, 8, 10, 11)]
botDS <- data.frame(botAcctlist$screenName, botAcctlist$id, botAcctlist$created, botAcctlist$statusesCount, langDiv = 0, mean_time_betwn_tweets = 0, bot = 0)
columnnames <- names(botDS)
columnnames[1] <- "screenName"
columnnames[2] <- "ID"
columnnames[3] <- "acct_created"
columnnames[4] <- "statusesCount"
colnames(botDS) <- columnnames
tweetsRT <- filter(recentTweetsDF, isRetweet == "TRUE")
tweetsOPEN <- filter(recentTweetsDF, isRetweet != "TRUE")
#tweeters <- unique(tweetsOPEN$screenName)
#length(tweeters)
botDS <- left_join(botDS, shredDF, by = "screenName")
groupedTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)
library(quanteda)
#using quanteda pkg - using the _TTR_ field as sole score
groupedTweetsDF$langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))$TTR
botDiv <- groupedTweetsDF %>%
group_by(screenName) %>%
summarise(meanDiv = mean(langDiv))
botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup
library(twitteR)
#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
#accts <- unlist(botDS$screenName)
#latestStat <- lookupUsers(accts)
latestStat <- readRDS("capstone dataset/latestStat")
latestStatDF <- twListToDF(latestStat)
latestStatDF$description <- iconv(latestStatDF$description, "latin1", "ASCII")
latestStatDF$name <- iconv(latestStatDF$name, "latin1", "ASCII")
latestStatDF$location <- iconv(latestStatDF$location, "latin1", "ASCII")
anchorDate <- as.Date("2018-01-12")
botDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(botDS$acct_created)
botDS$acct_age <- as.numeric(botDS$acct_age, units = "mins")
#botDS <- left_join(botDS[-4], latestStatDF[, c("screenName", "statusesCount")], by = "screenName")
botDS <- left_join(botDS[-4], latestStatDF, by = "screenName")
botDS$mean_time_betwn_tweets = botDS$acct_age/botDS$statusesCount #time measured in minutes
botDS <- botDS[, c(1, 6, 14, 16, 15, 18, 3, 12, 13, 4, 7, 9, 5, 8, 10, 11)]
#binning the account creation column
table(cut(botDS$acct_created, breaks = "6 month"))
names(botDS)
botDS21mar <- readRDS("capstone dataset.OLD/botDS.21march")
names(botDS21mar)
oldbot <- readRDS("capstone dataset.OLD/botDS.before.shredDF")
names(oldbot)
names(botDS)
names(groupedTweetsDF)
julian.POSIXt(anchorDate)
shredCVL <- readRDS("capstone dataset.OLD/shredCVL")
names(shredCVL)
groupTweetsDF <- tweetsOPEN %>%
group_by(screenName) %>%
filter(screenName %in% botDS$screenName)
rm(groupTweetsDF)
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang, na.rm = TRUE)
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))[,1]
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang, na.rm = TRUE)
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang, na.rm = TRUE)
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang[,1], na.rm = TRUE)
divLang
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang[,-1], na.rm = TRUE)
CTV$langDiv <- divMeans
#start compiling the interim dataframe with values desired for ETL
ctvDS <- data.frame(CTV$screen_name, CTV$bot, CTV$acct_created, "julianCreated", "acct_age", CTV$langDiv, "Count", "mean_time_betwn_tweets", "App", "App.BoN", "mCount", "Month")
ctvnames <- names(ctvDS)
ctvnames[1] <- "screenName"
ctvnames[2] <- "bot"
ctvnames[3] <- "acct_created"
ctvnames[4] <- "julianCreated"
ctvnames[5] <- "acct_age"
ctvnames[6] <- "langDiv"
ctvnames[7] <- "Count"
ctvnames[8] <- "mean_time_betwn_tweets"
ctvnames[9] <- "App"
ctvnames[10] <- "App.BoN"
ctvnames[11] <- "mCount"
ctvnames[12] <- "Month"
ctvDS$acct_age <- abs(as.numeric(ctvDS$acct_age, units = "mins"))
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang[,-1], na.rm = TRUE)
CTV$langDiv <- divMeans
#start compiling the interim dataframe with values desired for ETL
ctvDS <- data.frame(CTV$screen_name, CTV$bot, CTV$acct_created, "julianCreated", "acct_age", CTV$langDiv, "Count", "mean_time_betwn_tweets", "App", "App.BoN", "mCount", "Month")
ctvnames <- names(ctvDS)
ctvnames[1] <- "screenName"
ctvnames[2] <- "bot"
ctvnames[3] <- "acct_created"
ctvnames[4] <- "julianCreated"
ctvnames[5] <- "acct_age"
ctvnames[6] <- "langDiv"
ctvnames[7] <- "Count"
ctvnames[8] <- "mean_time_betwn_tweets"
ctvnames[9] <- "App"
ctvnames[10] <- "App.BoN"
ctvnames[11] <- "mCount"
ctvnames[12] <- "Month"
ctvDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(ctvDS$acct_created)
julian.POSIXt(ctvDS$acct_created
)
ctvDS
str(ctvDS)
names(CTV)
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang[,-1], na.rm = TRUE)
CTV$langDiv <- divMeans
#start compiling the interim dataframe with values desired for ETL
ctvDS <- data.frame(CTV$screen_name, CTV$bot, CTV$acct_created, "julianCreated", "acct_age" = 0, CTV$langDiv, "Count", "mean_time_betwn_tweets", "App", "App.BoN", "mCount", "Month")
ctvnames <- names(ctvDS)
ctvnames[1] <- "screenName"
ctvnames[2] <- "bot"
ctvnames[3] <- "acct_created"
ctvnames[4] <- "julianCreated"
ctvnames[5] <- "acct_age"
ctvnames[6] <- "langDiv"
ctvnames[7] <- "Count"
ctvnames[8] <- "mean_time_betwn_tweets"
ctvnames[9] <- "App"
ctvnames[10] <- "App.BoN"
ctvnames[11] <- "mCount"
ctvnames[12] <- "Month"
ctvDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(ctvDS$acct_created)
str(ctvDS)
julian.POSIXt(ctvDS$acct_created)
sessionInfo()
class(ctvDS$CTV.acct_created)
library(rtweet)
#CTV <- search_tweets(
#"#Charlottesville", n = 18000, include_rts = FALSE
#)
CTV <- readRDS("capstone dataset.OLD/CTV")
ts_plot(CTV)
#get some LISC values for the tweets (or CTV$text)
divLang <- as.data.frame(textstat_lexdiv(dfm(CTV$text)))
divLang[mapply(is.infinite, divLang)] <- NA
divLang[mapply(is.nan, divLang)] <- NA
divMeans <- rowMeans(divLang[,-1], na.rm = TRUE)
CTV$langDiv <- divMeans
#start compiling the interim dataframe with values desired for ETL
ctvDS <- data.frame(CTV$screen_name, CTV$bot, CTV$acct_created, "julianCreated", "acct_age" = 0, CTV$langDiv, "Count", "mean_time_betwn_tweets", "App", "App.BoN", "mCount", "Month")
ctvnames <- names(ctvDS)
ctvnames[1] <- "screenName"
ctvnames[2] <- "bot"
ctvnames[3] <- "acct_created"
ctvnames[4] <- "julianCreated"
ctvnames[5] <- "acct_age"
ctvnames[6] <- "langDiv"
ctvnames[7] <- "Count"
ctvnames[8] <- "mean_time_betwn_tweets"
ctvnames[9] <- "App"
ctvnames[10] <- "App.BoN"
ctvnames[11] <- "mCount"
ctvnames[12] <- "Month"
colnames(ctvDS) <- ctvnames
ctvDS$acct_age <- julian.POSIXt(anchorDate) - julian.POSIXt(ctvDS$acct_created)
ctvDS$acct_age <- abs(as.numeric(ctvDS$acct_age, units = "mins"))
colnames(ctvDS)
colnames(ctvDS) <- ctvnames
#perform a lookup of the user data in CTV
CTVstats <- users_data(CTV)
names(CTVstats)
#use those variables in CTVstats that will be needed in the final dataframe
CTVsub <- CTVstats[, c(3, 8:11, 21)]
names(ctvDS)
ctvDS$acct_age
CTVsub <- CTVstats[, c(3, 8:11, 21)]
names(CTVstats)
install.packages(c("aws.alexa", "config", "curl", "lme4", "selectr", "spam"))
names(CTVstats)
install.packages(c("mvtnorm","loo","coda"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
install_github("rmcelreath/rethinking",ref="Experimental")
library(devtools)
install_github("rmcelreath/rethinking",ref="Experimental")
options(repos=c(getOption('repos'), glmer2stan='http://xcelab.net/R'))
install.packages('glmer2stan',type='source')
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
cat("\nCXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function  -Wno-macro-redefined",
file = M, sep = "\n", append = TRUE)
cat("\nCC=clang",
"CXX=clang++ -arch x86_64 -ftemplate-depth-256",
file = M, sep = "\n", append = TRUE)
cat("\nCXXFLAGS+=-flto -Wno-unused-local-typedefs",
file = M, sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
Sys.setenv(MAKEFLAGS = "-j4")
install.packages(c("Rcpp", "rstan"), type = "source")
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
fx( 2L, 5 )
