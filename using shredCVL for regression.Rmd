---
title: "R Notebook"
geometry: "left=1cm,right=2cm,top=1cm,bottom=2cm"
output: pdf_document
---

```{r include=FALSE} 
knitr::opts_chunk$set(message = FALSE, warning = FALSE) 
```

```{r, message = FALSE}

library(rpart)
library(caret)
suppressMessages(library("tidyverse"))
library(rpart.plot)


shredCVL <- readRDS("capstone dataset/shredCVL")

```

```{r, message = FALSE, warning = FALSE}

table(shredCVL$bot)

in_train <- createDataPartition(y = shredCVL$bot, p = .75, list = FALSE)
testing_set <- shredCVL[-in_train,]
training_set <- shredCVL[in_train,]

str(training_set)
table(testing_set$bot)
table(training_set$bot)
121/654
390/1964

# both ratios hold to an 20:80 proportion.


model1 <- rpart(formula = bot ~., data = shredCVL, method = "class")

str(model1)
print(model1)

formula <- bot ~ statusesCount + friendsCount + followersCount + listedCount + acct_age + langDiv + mean_time_betwn_tweets + mCount

model2 <- rpart(formula, data = shredCVL, method = "class")

str(model2)
print(model2)

plotcp(model2)

rpart.plot(model2)

library(GGally)

ggpairs(training_set[,c(-1,-2,-7,-8,-12,-14)])

ggpairs(training_set[ , c('followersCount', 'friendsCount', 'acct_age', 
                  'langDiv', 'statusesCount', 'bot')])

ggplot(filter(training_set, followersCount < 100), 
       aes(x = followersCount, fill = bot)) +
  geom_histogram(binwidth = 3)

ggplot(filter(training_set, followersCount < 100), 
       aes(x = followersCount, fill = bot)) +
  geom_histogram(binwidth = 3) + 
  facet_grid(bot ~.)

# how about the number of people they follow?
ggplot(training_set, aes(x = friendsCount, fill = bot)) +
  geom_histogram(binwidth = 3000) +
  facet_grid(bot ~.)



# Some people have a lot of followers, but most don't. we need to lob off
# the long tail so we can see the distribution better
ggplot(filter(training_set, followersCount < 100), 
       aes(x = followersCount, fill = bot)) +
  geom_histogram()

ggplot(filter(training_set, followersCount < 100), 
       aes(x = followersCount, fill = bot)) +
  geom_histogram() + 
  facet_grid(bot ~.)

# how about the number of people they follow?
ggplot(training_set, aes(x = friendsCount, fill = bot)) +
  geom_histogram() +
  facet_grid(bot ~.)

# it's a little hard to see
ggplot(filter(training_set, friendsCount < 2500), 
       aes(x = friendsCount, fill = bot)) +
  geom_histogram() +
  facet_grid(bot ~.)

# what about account age?
ggplot(training_set, aes(x = acct_age, fill = bot)) +
  geom_histogram() +
  facet_grid(bot ~.)

# lexical diversity
ggplot(training_set, aes(x = langDiv, fill = bot)) +
  geom_histogram() +
  facet_grid(bot ~.)

# what are the average values?
meanDiv = 
  training_set %>%
    group_by(bot) %>%
    summarize(meanDiv = mean(langDiv, na.rm = TRUE))

# add it to the plot
ggplot(training_set, aes(x = langDiv, fill = bot)) +
  geom_histogram() +
  geom_vline(data = meanDiv, aes(xintercept = meanDiv)) + 
  facet_grid(bot ~.)


```

```{r, message = FALSE, warning = FALSE}

bagged_model = train(formula,
                    method = 'treebag',
                    data = training_set, na.action = na.omit)

print(bagged_model)
plot(varImp(bagged_model))

bagged_predictions = predict(bagged_model, testing_set)
#confusionMatrix(bagged_predictions, testing_set$bot)


```

```{r, message = FALSE, warning = FALSE}

boost_model = train(formula,
                    method = 'gbm',
                    data = training_set,
                    verbose = FALSE, na.action = na.omit)

print(boost_model)
plot(boost_model)
#plot(varImp(boost_model))

summary(boost_model$finalModel)

# predict
boost_predictions = predict(boost_model, testing_set)
#confusionMatrix(boost_predictions, testing_set$bot)
```

```{r, message = FALSE, warning = FALSE}
rf_model = train(formula, 
                 data = training_set, 
                 method = 'rf',
                 prox = TRUE,
                 verbose = TRUE, na.action = na.omit)


print(rf_model)
plot(rf_model)
plot(rf_model$finalModel)

# pull a tree out of the forest
head(randomForest::getTree(rf_model$finalModel, k = 5, labelVar = TRUE))

# predict
rf_predictions = predict(rf_model, testing_set)
#confusionMatrix(rf_predictions, testing_set$bot)

```

```{r, message = FALSE, warning = FALSE}

# Display the results
rpart.plot(x = model2, yesno = 2, type = 0, extra = 0)


# Train the model (to predict 'bot')
model3 <- rpart(formula, 
                      data = training_set, 
                      method = "class", na.action = na.omit)

# Look at the model output                      
print(model3)

#Evaluate performance
#library(caret)
# Generate predicted classes using the model object
class_prediction <- predict(object = model3,  
                            newdata = testing_set,   
                            type = "class")  

# Calculate the confusion matrix for the test set
#confusionMatrix(data = class_prediction,       
 #               reference = testing_set$default)  

#Minimize impurity measure - Gini Index
#Lower the Gini Index, higher the purity of the split
# Train a gini-based model
model31 <- rpart(formula, 
                       data = training_set, 
                       method = "class",
                       parms = list(split = 'gini'))

# Train an information-based model
model32 <- rpart(formula, 
                       data = training_set, 
                       method = "class",
                       parms = list(split = 'information'))

# Generate predictions on the validation set using the gini model
pred31 <- predict(object = model31, 
                 newdata = testing_set,
                 type = 'class')    

# Generate predictions on the validation set using the information model
pred32 <- predict(object = model32, 
                 newdata = testing_set,
                 type = "class")

```

```{r, message = FALSE, warning = FALSE}

# Display the results

rpart.plot(x = model31, yesno = 2, type = 0, extra = 0)
rpart.plot(x = model32, yesno = 2, type = 0, extra = 0)


######################

# Train the model (to predict 'bot')

modelClass <- rpart(formula, 
                      data = training_set, 
                      method = "class", na.action = na.omit)

# Look at the model output                      

print(modelClass)

#Evaluate performance
#library(caret)
# Generate predicted classes using the model object

class_prediction <- predict(object = modelClass,  
                            newdata = testing_set,   
                            type = "class")  

# Calculate the confusion matrix for the test set
confusionMatrix(data = class_prediction,       
                reference = testing_set$bot)  


#Minimize impurity measure - Gini Index
#Lower the Gini Index, higher the purity of the split
# Train a gini-based model

model41 <- rpart(formula, 
                       data = training_set, 
                       method = "class",
                       parms = list(split = 'gini'))

# Train an information-based model
model42 <- rpart(formula,
                       data = training_set, 
                       method = "class",
                       parms = list(split = 'information'))

# Generate predictions on the validation set using the gini model
pred41 <- predict(object = model41, 
                 newdata = testing_set,
                 type = 'class')    

# Generate predictions on the validation set using the information model
pred42 <- predict(object = model42, 
                 newdata = testing_set,
                 type = "class")

```

```{r}
# Compare classification error
library(Metrics)


ce(actual = testing_set$bot, 
   predicted = pred41)
ce(actual = testing_set$bot, 
   predicted = pred42)  
dt_preds <- pred42

```

```{r}

```




