---
title: "springboard capstone"
author: "milti leonard"
date: "7/9/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Detecting Bot Communities on Twitter and Determining Their Influence

Social media commands a tremendous influence on the ongoing zeitgeist, at times to the point of crafting and shaping it. This influence can have IRL (or real world) consequences and repercussions. The intent of the platform is to allow people of various backgrounds, but similar interests, to connect and form communities of the like-minded that is not limited by geospatial constraints. However, the reality is that various agents create and unleash *bot* accounts that disrupt those communities and alters the digital landscape making it at times a dark and hostile place.

This project will focus on a selected single *loaded* hashtag (meaning one whose LIWC is representative of a defined agenda) that command a respectable trending status to see whether or no it attracts these *bot* accounts and to what degree. Also to be investigated, is whether it is the human accounts or their *bot* counterparts that take the lead in establishing that trending status. I'm using as a roadmap Erin Shellman's class assignment on classifying whether a Twitter account is a bot or not, the problem statement (as well as a description of the dataset) can be found here, https://github.com/erinshellman/BI-TECH-CP303/blob/master/projects/project%202/problem_statement_project_2.md.

That project did not involve (nor describe) the gathering and ETL of the dataset presented to her students. The package I used to gather tweets to shape my dataset is as follows:

1. I leveraged another college project to first gather Twitter accounts denoted to be bots, *Debot*, found here, https://github.com/nchavoshi/debot_api. Using an API key I selected my *hashtag* ("Charlottesville) and collected a set of tweets that had used the *hashtag* and were determined (by this program) to be from *bot* accounts. This set included whether or no the *tweet* was a *retweet*, a *reply* or an original *tweet*. 

```{r, set-options, eval=FALSE, cache=FALSE}

library(reticulate)
library(XML)
#path_to_python <- "/usr/local/bin/python3.6"
path_to_python <- "/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6"
use_python(path_to_python)
dbot=import("debot")
db = dbot$DeBot('YocR3mKAc7U6hjKZrNnOCk2jjnWrqgSfwWYo8yOb')#This is my API key
cbots=htmlParse(db$get_related_bots('Charlottesville'))


#Now parse the XML data into a list of screennames or accounts.
botlist <- xmlToList(cbots)

library(listviewer)
flatbot <- flatten(botlist)
flatterbot <- flatten(flatbot)
remove(flatbot)
flatbot <- flatten(flatterbot)
newBotlist <- unname(sapply(flatbot, `[`, 2))

```

The *newBotlist* object is a nested list of 646 names:

R >  head(str(newBotlist)) 
List of 646
 $ : chr "15_margiecastro"
 $ : chr "2001shaira"
 $ : chr "78fb1da7564c40c"
 $ : chr "AaaRDieeee"
 ....
 
 
2. Utilising the _twitteR_ package, I used the extracted account names from the group of tweets gathered from *Debot* step and gathered information on the accounts themselves, such as when the account was created and the number of tweets thus far.


```{r, set-options, eval=FALSE, cache=FALSE}

library(twitteR)
library(ROAuth)


requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "dMs3guHk4y6DDdztO0JDmUTqB"
consumerSecret <- "csna8h6XWQMd3ZppMBCUuNNXDTuBAVJLNK7QphZRCd5plkES0z"
accessToken <- "1240280636-PTXARRUrytYtijYXyPWKptD9cHSCMzlAujQkATI"
accessTokenSecret <- "uo8INEJbhhe43AIXfSs5veSZ6i7IHbh8Tn1LLlYTJqOm2"
handle <- "conjja"

setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessTokenSecret)

botAccts <- lookupUsers(newBotlist)
## or just load the dataset: > botAccts <- load("capstone dataset/botAccts")

botAcctlist <- twListToDF(botAccts)
acctNames <- row.names.data.frame(botAcctlist)

```

The resulting dataframe was educed to 352 observations:

R >  str(botAcctlist)
'data.frame':	352 obs. of  17 variables:

Those variables are:

R >  names(botAcctlist)
 [1] "description"       "statusesCount"     "followersCount"    "favoritesCount"   
 [5] "friendsCount"      "url"               "name"              "created"          
 [9] "protected"         "verified"          "screenName"        "location"         
[13] "lang"              "id"                "listedCount"       "followRequestSent"
[17] "profileImageUrl"

We can see that several of the variables for the goal dataset are already in place: statusesCount, followersCount, etc. We're missing several variables listed in the Schellman's problem state referenced above. For convenience, let's list them here:

'data.frame':	3176 obs. of  15 variables:
 $ bot                     : int  0 0 0 0 0 0 0 0 0 0 ...
 $ statuses_count          : int  428 6239 80 12 4052 28 21 1379 2212 162 ...
 $ default_profile         : int  1 0 1 1 0 1 1 0 0 0 ...
 $ default_profile_image   : int  0 0 0 1 0 0 0 0 0 0 ...
 $ friends_count           : int  1867 896 161 1103 372 285 1555 291 2517 163 ...
 $ followers_count         : int  1680 372 54 140 387 31 192 184 3621 105 ...
 $ favourites_count        : int  0 4325 16 1 1751 0 15 188 212 340 ...
 $ geo_enabled             : int  0 1 0 0 1 0 1 0 1 0 ...
 $ listed_count            : int  29 4 15 1 21 1 0 9 145 6 ...
 $ account_age_hours       : int  3002 67482 23406 3676 14718 4898 2218 48548 57005 47479 ...
 $ diversity               : num  0.269 0.691 0.797 0.777 0.72 ...
 $ mean_mins_between_tweets: num  182 442 22847 4311 290 ...
 $ mean_tweet_length       : num  76 69.6 113.9 59.4 86.7 ...
 $ mean_retweets           : num  1.58 1.2 1.33 1 2.5 ...
 $ reply_rate              : num  0 0.2455 0.0492 0.5312 0.4419 ...

3. I then took the same accounts and gathered 200 of the most recent tweets (or as many as I could retrieve) from those accounts to get enough messaging to test the account's linguistic diversity.


```{r, set-options, eval=FALSE, cache=FALSE}

library(stringr)

recentTweetsDS <- map(unlistedBots[], ~searchTwitteR(.x, resultType = "recent", n=200))
recentTweetsDF <- twListToDF(flatten(recentTweetsDS))
AppURL <- rm_between_multiple(recentTweetsDF$statusSource,"<",">")
recentTweetsDF$App <- unlist(AppURL)
appcount <- recentTweetsDF%>%group_by(App)%>%summarize(Count=n())%>%arrange(desc(Count))
recentTweetsDF <- left_join(recentTweetsDF,appcount)
recentTweetsDF$BoN <- ifelse(recentTweetsDF$Count>4,0,1)
shredDF <- recentTweetsDF %>% select(screenName, AppURL, App, Count, BoN)
#shredDF <- recentTweetsDF %>% select(screenName, App, Count, BoN)

```

4. A new dataframe was created to contain the variables that we will consider interesting. Then in order to truly test the linguistic diversity of the account, it's important to separate the *tweets* from the *retweets*.

```{r, set-options, eval=FALSE, cache=FALSE}
botDS <- data.frame(botAcctlist$screenName, botAcctlist$id, botAcctlist$created, botAcctlist$statusesCount, langDiv = 0, mean_time_betwn_tweets = 0, bot = 0)
columnnames <- names(botDS)
columnnames[1] <- "screenName"
columnnames[2] <- "ID"
columnnames[3] <- "acct_created"
columnnames[4] <- "statusesCount"
colnames(botDS) <- columnnames

tweetsRT <- filter(recentTweetsDF, isRetweet == "TRUE")
tweetsOPEN <- filter(recentTweetsDF, isRetweet != "TRUE")
#tweeters <- unique(tweetsOPEN$screenName)
#length(tweeters)

botDS <- left_join(botDS, shredDF, by = "screenName")

botDS <- botDS[, c(1, 6, 14, 16, 15, 18, 3, 12, 13, 4, 7, 9, 5, 8, 10, 11)]


groupedTweetsDF <- tweetsOPEN %>%
  group_by(screenName) %>%
  filter(screenName %in% botDS$screenName)
castoffDF <- setdiff(tweetsOPEN, groupedTweetsDF)

#binning the account creation column
table(cut(botDS$acct_created, breaks = "6 month"))


```
Binning the creation times of these accounts doesn't uncover anything that interesting. Although, the 6 month period with the highest number, "2015-09-01", was in the months following DJT declaring himslef a candidate for the GOP nomination. Changing the size of the time bins, also highlights that the peak of account creation (for this set of suspected accounts) also have a noticeable peak immediately surrounding the time following the announcement.

The R packages that will be utilised in this study are as follows (with one or two being dropped, dependent on subsequent decisions made in the experimental design)

5. In this step, the linguistic diversity of the account is tested by taking the original *tweets* and averaging the 

```{r, set-options, eval=FALSE, cache=FALSE}
library(quanteda)

#using quanteda pkg
langDiv <- textstat_lexdiv(dfm(groupedTweetsDF$text))

botDiv <- groupedTweetsDF %>%
  group_by(screenName)
  summarise(meanDiv = mean(langDiv))

botDS <- left_join(botDS, botDiv)
botDS$langDiv <- botDS$meanDiv
#remove the meanDiv column for cleanup

#recreate latestStatDF code here where i get the latest statuses count for accounts to do mean_time_between_tweets variable
accts <- unlist(botDS$screenName)
latestStat <- lookupUsers(accts)
latestStatDF <- twListToDF(latestStat)

botDS$acct_age <- abs(as.numeric(botDS$acct_age, units = "mins"))
botDS <- left_join(botDS, latestStatDF[, c("screenName", "statusesCount")], by = "screenName")
botDS$mean_time_between_tweets = botDS$acct_age/botDS$statusesCount #time measured in minutes


```

```{r, set-options, eval=FALSE, cache=FALSE}

library(rtweet)

CTV <- search_tweets(
"#Charlottesville", n = 18000, include_rts = FALSE
)
ts_plot(CTV)

```

```{r, eval=FALSE}
#getting the source of the tweet (phone, web, other)
uniqSource <- unique(recentTweetsDF$statusSource)
inD <- which(str_detect(recentTweetsDF$statusSource, "Android"))
androidTweetsDF <- recentTweetsDF[inD,]

inD <- which(str_detect(recentTweetsDF$statusSource, "iP"))
iTweetsDF <- recentTweetsDF[inD,]

inD <- which(str_detect(recentTweetsDF$statusSource, "Web"))
webTweetsDF <- recentTweetsDF[inD,]

inD <- which(str_detect(recentTweetsDF$statusSource, paste(c("Android", "iP", "Web"), collapse = '|')))
otherTweetsDF <- recentTweetsDF[-inD,]

```

